#TO get urls
Create list.csv Column name NAME list what you want under NAME

```
python scrape_url_master.py list.csv
```
After collecting urls
Run
```
pthon download_from_json_master.py json_files
```
It will download images under images folder

#This repo is for creating a large scale image data set from World Wide Web.

Will need to install node modules
- async
- bluebird
- cheerio
- EventEmitter
- gm
- iconv
- limiter
- lupus
- nightmare
- request

Simple usage

```
node app.js
```
To use wordnet.py

Need to install nltk and nltk.download('all')

```
pip3 install nltk

```

Need to install imagemagick graphicsmagick for node gm


```
sudo apt-get install imagemagick graphicsmagick
```

